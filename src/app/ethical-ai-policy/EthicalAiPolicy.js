export default function EthicalAIPolicy() {
  return (
    <section className="w-full max-w-5xl mx-auto px-6 py-16 text-foreground">
      <h1 className="text-4xl font-bold mb-8">Ethical AI Policy</h1>
      <p className="mb-4 text-gray-400">Last Updated: Aug 30, 2025</p>

      <p className="mb-6">
        At <strong>Carlo PEaaS by Algorethics</strong>, we believe that artificial intelligence must always serve humanity in ways that are fair, transparent, accountable, and respectful of human dignity. Our Ethical AI Policy outlines the guiding values and operational commitments that underpin how we design, validate, and certify AI systems. This policy applies to all users, developers, and enterprises leveraging Carlo PEaaS for compliance and certification.
      </p>

      <p className="mb-6">
        Our responsibility goes beyond meeting legal standards; it includes embedding moral, cultural, and human-centered principles into every AI interaction. By working with Carlo PEaaS, you align your AI initiatives with these ethical commitments.
      </p>

      <hr className="my-8 border-gray-600" />

    
      <section className="mb-8">
        <h2 className="text-2xl font-semibold mb-4">1. Core Commitments</h2>
        <p className="mb-2">Carlo PEaaS is built on five foundational pillars:</p>
        <ul className="list-disc list-inside space-y-1">
          <li><strong>Fairness</strong> â€“ We actively identify and mitigate algorithmic bias, ensuring AI models do not discriminate based on race, gender, religion, age, disability, or other protected attributes. Fairness assessments are embedded in our validation pipelines, and bias detection forms a critical part of certification.</li>
          <li><strong>Transparency</strong> â€“ Carlo enforces explainability standards for AI systems, particularly for high-risk applications under the EU AI Act. Every compliance check generates detailed logs, providing regulators, users, and stakeholders with visibility into how AI decisions are made.</li>
          <li><strong>Accountability</strong> â€“ We support full audit readiness by producing compliance logs, policy documentation, and certification trails. Human oversight remains central, ensuring that automated decisions never bypass accountability mechanisms.</li>
          <li><strong>Human Dignity</strong> â€“ Carlo requires that AI systems respect fundamental rights and freedoms. Use cases that compromise safety, privacy, or human dignityâ€”such as unlawful surveillance or exploitative profilingâ€”are explicitly disallowed.</li>
          <li><strong>Inclusivity</strong> â€“ Our platform supports multi-faith, cross-cultural, and sector-specific frameworks, ensuring that ethical principles reflect the diversity of global communities and industries. Inclusivity extends to both datasets and decision-making outcomes.</li>
        </ul>
      </section>

     
      <section className="mb-8">
        <h2 className="text-2xl font-semibold mb-4">2. Framework Alignment</h2>
        <ul className="list-disc list-inside space-y-1">
          <li>Rome Call for AI Ethics â€“ Upholding transparency, inclusiveness, accountability, impartiality, and security as endorsed by faith and cultural leaders.</li>
          <li>EU AI Act & GDPR â€“ Ensuring lawful, safe, and trustworthy use of AI across the European Union, with data protection and compliance obligations fully embedded.</li>
          <li>OECD AI Principles â€“ Promoting human-centered values, sustainable development, and international collaboration.</li>
          <li>UN Guiding Principles on Business & Human Rights â€“ Mandating respect for human rights in AI deployment.</li>
          <li>Industry-Specific Standards â€“ Covering healthcare, finance, defense, IoT, and retail, ensuring compliance with both regulatory and ethical requirements.</li>
        </ul>
        <p className="mt-2">By combining these frameworks, Carlo provides a unified, global compliance lens, ensuring that AI models deployed across borders remain safe, ethical, and regulation-proof.</p>
      </section>

     
      <section className="mb-8">
        <h2 className="text-2xl font-semibold mb-4">3. Developer & Enterprise Responsibilities</h2>
        <ul className="list-disc list-inside space-y-1">
          <li>Integrating compliance checks â€“ Embedding Carloâ€™s validation tools into their AI workflows, ensuring compliance throughout development, deployment, and monitoring.</li>
          <li>Avoiding unethical applications â€“ Refraining from deploying AI in contexts that may cause harm, discrimination, misinformation, or human rights violations.</li>
          <li>Upholding transparency â€“ Providing clear documentation, disclosures, and explainability for AI-driven decisions, especially in sensitive or high-risk environments.</li>
          <li>Maintaining accountability â€“ Recognizing that Carlo assists in compliance, but ultimate responsibility for lawful and ethical use of AI remains with the developer or enterprise.</li>
          <li>Engaging in continuous improvement â€“ Adapting AI systems as laws, ethical norms, and societal expectations evolve. Carlo will provide policy updates, but it is the developerâ€™s duty to integrate these into ongoing operations.</li>
        </ul>
      </section>

   
      <section className="mb-8">
        <h2 className="text-2xl font-semibold mb-4">4. Prohibited AI Use Cases</h2>
        <ul className="list-disc list-inside space-y-1">
          <li>Autonomous weapons and lethal decision-making systems.</li>
          <li>Mass surveillance technologies deployed without lawful oversight.</li>
          <li>Social scoring and exploitative behavioral manipulation.</li>
          <li>AI applications designed for fraud, misinformation, or disinformation campaigns.</li>
          <li>Systems that intentionally violate fundamental rights, labor protections, or democratic values.</li>
        </ul>
      </section>

     
      <section className="mb-8">
        <h2 className="text-2xl font-semibold mb-4">5. Commitment to Continuous Ethics</h2>
        <ul className="list-disc list-inside space-y-1">
          <li>Ongoing monitoring of AI model outputs.</li>
          <li>Feedback loops for reporting ethical concerns.</li>
          <li>Dynamic updates to compliance frameworks as global standards evolve.</li>
          <li>Collaborations with academic, legal, and cultural institutions to refine ethical practices.</li>
        </ul>
      </section>

     
      <section className="mb-8">
        <h2 className="text-2xl font-semibold mb-4">6. Contact Information</h2>
        <p>If you have concerns about ethical practices, misuse of AI systems, or want to report potential violations, please contact:</p>
        <p className="mt-2 font-medium">ðŸ“§ info@algorethics.ai</p>
        <p className="mt-2">All reports will be handled with confidentiality, transparency, and seriousness, ensuring corrective action where necessary.</p>
      </section>
    </section>
  );
}
